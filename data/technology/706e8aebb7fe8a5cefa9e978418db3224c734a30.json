{"author": "Min Cai", "title": "Open Sourcing Peloton, Uber’s Unified Resource Scheduler", "description": "", "url": "https://eng.uber.com/open-sourcing-peloton/", "urlToImage": "https://eng.uber.com/wp-content/uploads/2019/03/Peloton-header.jpg", "publishedAt": "2019-03-15T14:18:48Z", "content": "                                           Skip to footer         Uber Engineering logo   Engineering    Menu    Menu  AI  Architecture  Culture  General Engineering  Mobile  Open Source  Uber Data   Uber Links  Uber.com  Uber Eats  UberRUSH  Uber for Business  Help  Newsroom  Careers  Uber Open Source   Follow Us             Magnifying glass indicating a search icon        To search this site, enter a search term      Magnifying glass indicating a search icon             Architecture Open Source   Open Sourcing Peloton, Uber’s Unified Resource Scheduler    Min Cai and Mayank Bansal   March 8, 2019             Email    Print       First introduced by Uber in November 2018, Peloton , a unified resource scheduler, manages resources across distinct workloads, combining separate compute clusters. Peloton is designed for web-scale companies like Uber with millions of containers and tens of thousands of nodes. Peloton features advanced resource management capabilities such as elastic resource sharing, hierarchical max-min fairness, resource overcommits, and workload preemption. As a cloud-agnostic system, Peloton can be run in on-premise data centers or in the cloud.  At Uber, Peloton is a critical piece of infrastructure powering our compute clusters. It is currently running many kinds of batch workloads in production, and we are planning to migrate stateless services workloads to it as well.  Today, Uber is excited to announce that we are open sourcing Peloton. By allowing others in the cluster management community to leverage unified schedulers and workload co-location, Peloton will open the door for more efficient resource utilization and management across the community. Moreover, open sourcing Peloton will enable greater industry collaboration and open up the software to feedback and contributions from industry engineers, independent developers, and academics across the world.  Benefits of using Peloton  To our knowledge, there is no other open source scheduler which combines all types of workloads for web-scale companies like Uber. Prior to Peloton, each workload at Uber had its own cluster, resulting in many inefficiencies. With Peloton, we can colocate mixed workloads in shared clusters for better resource utilization.  As shown by the Google Borg paper , co-locating diverse workloads on shared clusters is key to improving cluster utilization and reducing overall cluster cost . Below, we outline some examples of how co-locating mixed workloads will drive utilization in our compute clusters, as well as helps us more accurately plan cluster provisioning:   Resource overcommitment and job preemption are key to improving cluster resource utilization. However, it is very expensive to preempt online jobs, such as stateless or stateful services that are often latency sensitive. Hence, preventing preemption of these latency-sensitive jobs requires us to co-locate batch jobs that are low-priority and preemptible on the same cluster, enabling us to better utilize overcommitted resources.  As Uber services move towards an active-active architecture , we will have capacity reserved for disaster recovery (DR) in each data center. That DR capacity can be used for batch jobs until data center failover occurs. Also, sharing clusters with mixed workloads means we no longer need to buy extra DR capacity for online and batch workloads separately.  Uber’s online workloads spike during big events like Halloween or New Year’s Eve . We need to plan capacity for these high-traffic events well in advance, requiring us to buy hardware separately for online and batch jobs. During the rest of the year, this extra hardware is underutilized, leading to extra, and unnecessary, technical costs. By co-locating both workloads on the same cluster, we can lend capacity from batch workloads to online workloads for those spikes without buying extra hardware.  Different workloads have resource profiles that are often complementary to each other. For example, stateful services or batch jobs might be disk IO intensive but stateless services often use little disk IO. Given these profiles, it makes more sense to co-locate stateful services with batch jobs on the same cluster.   Realizing that these scenarios would enable us to achieve greater operational efficiency, improve capacity planning, and optimize resource sharing, it was evident that we needed to co-locate different workloads together on one single, shared compute platform. A unified resource scheduler will enable us to manage all kinds of workloads to use our resources as efficiently as possible both in private data centers and the cloud.  Peloton will support Uber’s workloads with a single, shared platform, balancing resource usage by elastically sharing resources, and helping teams better plan for future capacity needs. Learn more about these benefits by reading our recent article on Peloton.  Features in the current release  Uber has been running Peloton in production for more than a year and it’s scaling and running very well. Below are some of the feature highlights.   Elastic Resource Sharing : Support hierarchical resource pools to elastically share resources among different teams.  Resource Overcommit and Task Preemption : Improve cluster utilization by scheduling workloads using slack resources and preempting best effort workloads.  Optimized for Big Data Workloads : Support advanced Apache Spark features such as dynamic resource allocation.  Optimized for Machine Learning : Support GPU and Gang scheduling for TensorFlow and Horovod . Manage thousands of GPUs in production  Protobuf/gRPC-based API : Support most of the language bindings such as Golang, Java, Python, and Node.js.  Co-scheduling Mixed Workloads : Support mixed workloads such as batch, stateless, and stateful jobs in a single cluster.  High Scalability : Scale to millions of containers and tens of thousands of nodes as shown in our benchmark tests in our recent Kubecon Talk .   Uber’s Peloton team is also working on stateless service support, coming soon. Please visit the Next Steps section of our article on Peloton for more details.  Get started  We hope you try out Peloton for yourself ! Learn more by reading our recent article on Peloton and our documentation or joining our Slack channel with any questions about the software.   Comments  Tweet Share Share Vote Reddit +1     TAGS Active-Active Architecture Compute Compute Cluster Compute Platform Kubernetes Mesos OSS Peloton Resource Scheduling scalability Uber Engineering Uber Open Source   Previous article Using Machine Learning to Ensure the Capacity Safety of Individual Microservices Next article Mitigating Risk in a Three-Sided Marketplace: A Conversation with Trupti Natu and Neel Mouleeswaran on the Uber Eats Risk Team         Min Cai   Min Cai is a senior staff engineer on Uber's Compute Cluster Platform team.               Mayank Bansal   Mayank Bansal is a staff engineer on Uber's Big Data team.         Related Articles More from Author         Introducing Makisu: Uber’s Fast, Reliable Docker Image Builder for Apache Mesos and Kubernetes            Engineering Uber’s Next-Gen Payments Platform            Open Source at Uber: A Conversation with Yuri Shkuro, Jaeger Project Lead             Architects of Infrastructure: Meet Uber Aarhus Engineering                  Popular Articles      Uber’s Big Data Platform: 100+ Petabytes with Minute Latency   October 17, 2018           Introducing Ludwig, a Code-Free Deep Learning Toolbox   February 11, 2019           Meet Michelangelo: Uber’s Machine Learning Platform   September 5, 2017           Introducing AresDB: Uber’s GPU-Powered Open Source, Real-time Analytics Engine   January 29, 2019           Why Uber Engineering Switched from Postgres to MySQL   July 26, 2016           Forecasting at Uber: An Introduction   September 6, 2018           Scaling Machine Learning at Uber with Michelangelo   November 2, 2018           Introducing Kraken, an Open Source Peer-to-Peer Docker Registry   March 5, 2019           Michelangelo PyML: Introducing Uber’s Platform for Rapid Python ML Model Development   October 23, 2018           Montezuma’s Revenge Solved by Go-Explore, a New Algorithm for Hard-Exploration Problems...   November 26, 2018        Categories  AI   Announcement   Architecture   Culture   Developers   Events   General Engineering   Mobile   Open Source   Team Profile   Uber Data                Uber logo Engineering     Sign up to ride A chevron arrow that was created with the Uber Move font  Get the App A chevron arrow that was created with the Uber Move font    Sign up to drive A chevron arrow that was created with the Uber Move font  Become a Driver A chevron arrow that was created with the Uber Move font       Contact Us  ubereng@uber.com  @ubereng  UberEngineering  Uber Engineering  UberEngineering  UberEngineering     Uber Engineering Blog Categories  AI  Architecture  Culture  Developers  General Engineering  Mobile  Open Source  Team Profile  Uber Data     Uber Links  Uber.com  Uber Eats  UberRUSH  Uber for Business  Help  Newsroom  Careers  Uber Open Source      © 2019 Uber Technologies Inc.  Privacy Policy  Terms and Conditions       MORE STORIES     Mastermind: Using Uber Engineering to Combat Fraud in Real Time    Yifu Diao ,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tand Isabel Geracioti   March 8, 2017       Engineering Safety with Uber’s Real-Time ID Check    Nitin Bajaj , Shimul Sachdeva ,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tand Dima Kovalev   March 13, 2017       Presenting the Engineering Behind Uber at Our Technology Day    Stephanie Romo   April 7, 2017       Uber in the Big Apple: Meet New York City Engineering    Amy San Felipe   April 24, 2017      Tweet Share Share Vote Reddit", "category": "technology"}